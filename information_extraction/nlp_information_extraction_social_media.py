# -*- coding: utf-8 -*-
"""assignment_social_media_information_extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FoenlkKjipK5_CnCl5bHaXO4i0_HvELQ
"""

import spacy
import os
import pandas as pd
import re
from spacy.matcher import Matcher

twitter_data = pd.read_csv("/content/Demonatization_tweets.csv", encoding='unicode_escape')

nlp=spacy.load('en_core_web_sm')

def print_data_summary(df):
    print(df.info())
    print(df.shape)
    print(df.head(2))
    print(df.tail(2))

print_data_summary(twitter_data)

twitter_data = twitter_data.rename(columns={"Unnamed: 0": "tweet_number", "text": "tweet"}, errors="raise")
print_data_summary(twitter_data)

#Look at the top 50 mentions in the dataset (mentions in this dataset refers to the @s)

def mention(x):
    found = re.findall(r'@\w+',x)
    if found:
        return found
    return None

mentions = twitter_data['tweet'].apply(lambda x: mention(x))
#print(mentions.head())

#combine all mentions in a list
mentions_list = []

for x in mentions:
    if x != None:
        mentions_list.extend(x)

#print(mentions_list)
mentions_count = pd.Series(mentions_list).value_counts().head(50)
print (mentions_count)

#Find the top 50 most frequently used hashtags (#)

def hashtag(x):
    found = re.findall(r'#\w+',x)
    if found:
        return found
    return None

hashtags = twitter_data['tweet'].apply(lambda x: hashtag(x))
#print(hashtags.head())

#combine all hashtags in a list
hashtags_list = []

for x in hashtags:
    if x != None:
        hashtags_list.extend(x)

#print(hashtags_list)
hashtags_count = pd.Series(hashtags_list).value_counts().head(50)
print (hashtags_count)

# Find the sentences having mentions of Prime Minister
def find_names(text):

    names = []

    # spacy doc
    doc = nlp(text)

    # pattern
    pattern = [{'LOWER':'prime'},
              {'LOWER':'minister'},
              {'POS':'ADP','OP':'?'},
              {'POS':'PROPN'}]

    # Matcher class object
    matcher = Matcher(nlp.vocab)
    matcher.add("pm_names", [pattern])

    matches = matcher(doc)

    # finding patterns in the text
    for i in range(0,len(matches)):

        # match: id, start, end
        token = doc[matches[i][1]:matches[i][2]]
        #print(token)
        # append token to list
        names.append(str(token))

    return names

# apply function
#pm_names = twitter_data['tweet'].apply(find_names)

#extracting sentences with PM names
extracted_pm_names = []
for i in range(twitter_data.shape[0]):
    #print(twitter_data.loc[i]['tweet']", twitter_data.loc[i]['tweet'])
    #print("twitter_data['tweet'][i]", twitter_data['tweet'][i])
    extracted_pm_names.append(find_names(twitter_data['tweet'][i]))

twitter_data['pm_name'] = extracted_pm_names

#extracting only the not null values
mention = []
for i in range(twitter_data.shape[0]):
    if twitter_data['pm_name'][i] != []:
        mention.append(twitter_data['pm_name'][i])

print(mention)

#extracting the sentences which have Prime Minister mentioned
sentences_pm = []
for i in range(twitter_data.shape[0]):
    if twitter_data['tweet'][i] != []:
        sentences_pm.append(twitter_data['tweet'][i])

print(sentences_pm)

#Use the prepositions to extract relevant information from the tweets
def find_prepositions(text):

    sent = []

    # spacy doc
    doc = nlp(text)

    for token in doc:
        if token.pos_ == 'ADP':
            phrase = ''
            #if the head word is a noun
            if token.head.pos_ == 'NOUN':
                phrase += token.head.text
                phrase += ' '+token.text

            #check nodes to the right of the preposition
            for right_tok in token.rights:
                #append if it is a noun or a pronoun
                if right_tok.pos_ in ('NOUN', 'PROPN'):
                    phrase += ' '+right_tok.text
            count_spaces = 0
            for i in range(0, len(phrase)):
                if phrase[i] == " ":
                    count_spaces += 1
            if count_spaces > 2:
                sent.append(phrase)
    #print(sent)
    return sent

preposition_data_row_list = []
for i in range(twitter_data.shape[0]):
    tweet_number = twitter_data.loc[i]['tweet_number']
    tweet = twitter_data.loc[i]['tweet']
    preposition_data = find_prepositions(tweet)
    #print(preposition_data)
    if len(preposition_data) > 0:
        dict1 = {'tweet_number': tweet_number, 'tweet':tweet, 'preposition_data':preposition_data}
        #print(dict1)
        preposition_data_row_list.append(dict1)
df_preposition = pd.DataFrame(preposition_data_row_list)
print(df_preposition.head())

